seed: 12345
work_dir: ${hydra:runtime.cwd}
debug: false
print_config: true
ignore_warnings: true
trainer:
  _target_: pytorch_lightning.Trainer
  min_epochs: 100
  max_epochs: 150
  log_every_n_steps: 1
  num_sanity_val_steps: 2
  accumulate_grad_batches: 3
  strategy: ddp
  accelerator: gpu
  devices: 2
datamodule: hdf5_datamodule_rgb
dataset_description:
  _convert_: all
  classification_preprocessing_dict:
    3: 5
    4: 5
    160: 64
    161: 64
    162: 64
    0: 1
    7: 1
    46: 1
    47: 1
    48: 1
    49: 1
    50: 1
    51: 1
    52: 1
    53: 1
    54: 1
    55: 1
    56: 1
    57: 1
    58: 1
    66: 1
    67: 1
    77: 1
    155: 1
    204: 1
  classification_dict:
    1: unclassified
    2: ground
    5: vegetation
    6: building
    9: water
    17: bridge
    64: lasting_above
  class_weights:
  - 0.25
  - 0.1
  - 0.1
  - 0.5
  - 2.0
  - 2.0
  - 2.0
  d_in: 9
  num_classes: 7
callbacks:
  log_code:
    _target_: src.callbacks.comet_callbacks.LogCode
    code_dir: ${work_dir}/src
  log_logs_dir:
    _target_: src.callbacks.comet_callbacks.LogLogsPath
  lr_monitor:
    _target_: pytorch_lightning.callbacks.LearningRateMonitor
    logging_interval: step
    log_momentum: true
  log_iou_by_class:
    _target_: src.callbacks.logging_callbacks.LogIoUByClass
    classification_dict: ${dataset_description.classification_dict}
  model_checkpoint:
    _target_: pytorch_lightning.callbacks.ModelCheckpoint
    monitor: val/loss_epoch
    mode: min
    save_top_k: 1
    save_last: true
    verbose: true
    dirpath: checkpoints/
    filename: epoch_{epoch:03d}
    auto_insert_metric_name: false
  early_stopping:
    _target_: pytorch_lightning.callbacks.EarlyStopping
    monitor: val/loss_epoch
    mode: min
    patience: 6
    min_delta: 0
model:
  optimizer:
    _target_: functools.partial
    _args_:
    - ${get_method:torch.optim.Adam}
    lr: ${model.lr}
  lr_scheduler:
    _target_: functools.partial
    _args_:
    - ${get_method:torch.optim.lr_scheduler.ReduceLROnPlateau}
    mode: min
    factor: 0.5
    patience: 20
    cooldown: 5
    verbose: true
  criterion:
    _target_: torch.nn.CrossEntropyLoss
    label_smoothing: 0.0
  _target_: src.models.model.Model
  d_in: ${dataset_description.d_in}
  num_classes: ${dataset_description.num_classes}
  ckpt_path: null
  neural_net_class_name: PyGRandLANet
  neural_net_hparams:
    num_features: ${model.d_in}
    num_classes: ${model.num_classes}
    num_neighbors: 16
    decimation: 4
    return_logits: true
  interpolation_k: ${predict.interpolator.interpolation_k}
  num_workers: 4
  iou:
    _target_: functools.partial
    _args_:
    - ${get_method:torchmetrics.JaccardIndex}
    - ${model.num_classes}
    absent_score: 1.0
  momentum: 0.9
  monitor: val/loss_epoch
  lr: 0.003933709606504788
logger:
  comet:
    _target_: pytorch_lightning.loggers.comet.CometLogger
    api_key: ${oc.env:COMET_API_TOKEN}
    workspace: ${oc.env:COMET_WORKSPACE}
    project_name: ${oc.env:COMET_PROJECT_NAME}
    experiment_name: '[V3.0.2-BS10xMAX40000pts] RandLaNet_base_run_FR_pyg_randla_net_NoRS'
    auto_log_co2: false
    disabled: true
task:
  task_name: predict
  auto_lr_find: false
predict:
  src_las: data/colorized_las/merged_colorized.las
  output_dir: data/test
  ckpt_path: assets/proto151_V2.0_epoch_100_Myria3DV3.1.0.ckpt
  subtile_overlap: 0
  gpus: 1
  interpolator:
    _target_: src.models.interpolation.Interpolator
    interpolation_k: 10
    classification_dict: ${dataset_description.classification_dict}
    probas_to_save:
    - building
    - ground
    predicted_classification_channel: confidence
    entropy_channel: entropy
ckpt_path: assets/proto151_V2.0_epoch_100_Myria3DV3.1.0.ckpt
